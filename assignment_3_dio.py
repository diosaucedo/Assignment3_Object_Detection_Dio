# -*- coding: utf-8 -*-
"""Assignment 3 Dio.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-6UXN4GuBg0AXVz2RkRNOXdljrww9fHY
"""

# Step 1: Install required libraries
!pip install ultralytics torch torchvision opencv-python pandas numpy

# Step 2: Import necessary libraries
from ultralytics import YOLO
from PIL import Image
import matplotlib.pyplot as plt
import os
import pandas as pd
import time  # For tracking detection time
from google.colab import drive

# Step 3: Mount Google Drive
drive.mount('/content/drive')

# Step 4: Initialize YOLO model (using YOLOv8 Medium weights)
model = YOLO("yolov8m.pt")

# Path to the folder containing the images
image_folder = "/content/drive/MyDrive/Assignment3"

# Get list of images (only jpg, png, or jpeg files)
image_paths = [os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.endswith(('.jpg', '.jpeg', '.png'))]

# Limit the number of images to process to 7
image_paths = image_paths[:7]

# Step 5: Results storage
results_list = []

# Step 6: Loop through each image, predict, annotate, and save the results
for i, image_path in enumerate(image_paths):
    try:
        print(f'Processing {image_path}...')

        # Start the timer
        start_time = time.time()

        # Run YOLO prediction on the image
        results = model.predict(image_path)
        result = results[0]  # The result contains detected objects

        # Stop the timer and calculate detection time
        detection_time = time.time() - start_time

        # Annotate the image with YOLO-detected objects
        annotated_image = result.plot()

        # Display the annotated image
        plt.figure(figsize=(10, 10))
        plt.imshow(annotated_image)
        plt.axis('off')  # Turn off the axes for better visualization
        plt.title(f"Image {i+1}: {os.path.basename(image_path)}")
        plt.show()

        # Convert the NumPy array to a PIL Image
        annotated_image_pil = Image.fromarray(annotated_image)

        # Save the annotated image to Google Drive
        output_path = os.path.join(image_folder, f"annotated_image_{i+1}.jpg")
        annotated_image_pil.save(output_path)

        print(f"Annotated image saved as: {output_path}\n")

        # Extract detection information from YOLO results
        num_objects = len(result.boxes)
        classes = result.boxes.cls.tolist()
        confidences = result.boxes.conf.tolist()

        # Convert class indices to YOLO class names
        class_names = [model.names[int(cls)] for cls in classes]

        # Store results for this image
        results_list.append({
            'Image': os.path.basename(image_path),
            'Detection Time (s)': round(detection_time, 2),
            'Number of Objects Detected': num_objects,
            'Classes Detected': class_names,
            'Confidence Probabilities': [round(conf, 4) for conf in confidences]
        })

    except Exception as e:
        print(f"Error processing {image_path}: {e}")

# Step 7: Create a DataFrame to store and display the results
results_df = pd.DataFrame(results_list)

# Display results as a table
print("\nResults Table")
display(results_df)

# Step 8: Save the results as a CSV file in your Google Drive
csv_path = '/content/drive/MyDrive/Assignment3/object_detection_results.csv'
results_df.to_csv(csv_path, index=False)

# Print the location of the saved file
print(f"\nResults have been saved to: {csv_path}")

# Step 1: Install required libraries
!pip install torch torchvision opencv-python pandas numpy

# Step 2: Import necessary libraries
import torch
import torchvision
from torchvision.transforms import functional as F
from PIL import Image, ImageDraw, ImageFont
import matplotlib.pyplot as plt
import os
import pandas as pd
import time  # For tracking detection time
from google.colab import drive

# Step 3: Mount Google Drive
drive.mount('/content/drive')

# Step 4: Initialize Faster R-CNN model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
faster_rcnn_model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True).to(device)
faster_rcnn_model.eval()  # Set model to evaluation mode

# Path to the folder containing the images
image_folder = "/content/drive/MyDrive/Assignment3"

# Get list of images (only jpg, png, or jpeg files)
image_paths = [os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.endswith(('.jpg', '.jpeg', '.png'))]

# Limit the number of images to process to 7
image_paths = image_paths[:7]

# Step 5: Results storage
results_list = []

# Step 6: Loop through each image, predict, annotate, and save the results
for i, image_path in enumerate(image_paths):
    try:
        print(f'Processing {image_path}...')

        # Load the image and convert it to tensor
        image = Image.open(image_path).convert("RGB")
        image_tensor = F.to_tensor(image).unsqueeze(0).to(device)  # Convert to tensor and add batch dimension

        ####### FASTER R-CNN #######
        # Start the timer
        start_time = time.time()

        # Run Faster R-CNN prediction
        with torch.no_grad():
            faster_rcnn_results = faster_rcnn_model(image_tensor)

        # Stop the timer and calculate detection time
        detection_time_faster_rcnn = time.time() - start_time

        # Extract information from Faster R-CNN results
        num_objects_faster_rcnn = len(faster_rcnn_results[0]['labels'])
        boxes = faster_rcnn_results[0]['boxes'].tolist()
        classes_faster_rcnn = faster_rcnn_results[0]['labels'].tolist()
        confidences_faster_rcnn = faster_rcnn_results[0]['scores'].tolist()

        # Get class names from COCO dataset (optional)
        class_names_faster_rcnn = [f"Class_{cls}" for cls in classes_faster_rcnn]

        # Draw bounding boxes and class labels on the image
        image_annotated = image.copy()
        draw = ImageDraw.Draw(image_annotated)

        # Use default font
        try:
            font = ImageFont.truetype("arial.ttf", 20)
        except:
            font = ImageFont.load_default()

        for box, label, score in zip(boxes, classes_faster_rcnn, confidences_faster_rcnn):
            x1, y1, x2, y2 = box
            draw.rectangle([x1, y1, x2, y2], outline="red", width=2)
            label_text = f"{f'Class_{label}'}: {score:.2f}"

            # Calculate the size of the text to create a background
            text_bbox = font.getbbox(label_text)
            text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]
            text_background = [x1, y1 - text_height, x1 + text_width, y1]

            draw.rectangle(text_background, fill="red")
            draw.text((x1, y1 - text_height), label_text, fill="white", font=font)

        # Display the image with bounding boxes
        plt.figure(figsize=(10, 10))
        plt.imshow(image_annotated)
        plt.axis('off')  # Turn off the axes for better visualization
        plt.title(f"Image {i+1}: {os.path.basename(image_path)}")
        plt.show()

        # Save the annotated image to Google Drive
        output_path = os.path.join(image_folder, f"annotated_faster_rcnn_image_{i+1}.jpg")
        image_annotated.save(output_path)

        print(f"Annotated image saved as: {output_path}\n")

        # Store results for this image
        results_list.append({
            'Image': os.path.basename(image_path),
            'Faster R-CNN Detection Time (s)': round(detection_time_faster_rcnn, 2),
            'Faster R-CNN Objects Detected': num_objects_faster_rcnn,
            'Faster R-CNN Classes Detected': class_names_faster_rcnn,
            'Faster R-CNN Confidence Probabilities': [round(conf, 4) for conf in confidences_faster_rcnn],
        })

    except Exception as e:
        print(f"Error processing {image_path}: {e}")

# Step 7: Create a DataFrame to store and display the results
results_df = pd.DataFrame(results_list)

# Display results as a table
print("\nResults Table")
display(results_df)

# Step 8: Save the results as a CSV file in your Google Drive
csv_path = '/content/drive/MyDrive/Assignment3/faster_rcnn_object_detection_results.csv'
results_df.to_csv(csv_path, index=False)

# Print the location of the saved file
print(f"\nResults have been saved to: {csv_path}")

# Step 1: Install required libraries
!pip install torch torchvision opencv-python pandas numpy

# Step 2: Import necessary libraries
import torch
import torchvision
from torchvision.transforms import functional as F
from PIL import Image, ImageDraw, ImageFont
import matplotlib.pyplot as plt
import os
import pandas as pd
import time  # For tracking detection time
from google.colab import drive

# Step 3: Mount Google Drive
drive.mount('/content/drive')

# Step 4: Initialize Mask R-CNN model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
mask_rcnn_model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True).to(device)
mask_rcnn_model.eval()  # Set model to evaluation mode

# Path to the folder containing the images
image_folder = "/content/drive/MyDrive/Assignment3"

# Get list of images (only jpg, png, or jpeg files)
image_paths = [os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.endswith(('.jpg', '.jpeg', '.png'))]

# Limit the number of images to process to 7
image_paths = image_paths[:7]

# Step 5: Results storage
results_list = []

# Step 6: Loop through each image, predict, annotate, and save the results
for i, image_path in enumerate(image_paths):
    try:
        print(f'Processing {image_path}...')

        # Load the image and convert it to tensor
        image = Image.open(image_path).convert("RGB")
        image_tensor = F.to_tensor(image).unsqueeze(0).to(device)  # Convert to tensor and add batch dimension

        ####### MASK R-CNN #######
        # Start the timer
        start_time = time.time()

        # Run Mask R-CNN prediction
        with torch.no_grad():
            mask_rcnn_results = mask_rcnn_model(image_tensor)

        # Stop the timer and calculate detection time
        detection_time_mask_rcnn = time.time() - start_time

        # Extract information from Mask R-CNN results
        num_objects_mask_rcnn = len(mask_rcnn_results[0]['labels'])
        boxes = mask_rcnn_results[0]['boxes'].tolist()
        classes_mask_rcnn = mask_rcnn_results[0]['labels'].tolist()
        confidences_mask_rcnn = mask_rcnn_results[0]['scores'].tolist()

        # Get class names from COCO dataset (optional)
        class_names_mask_rcnn = [f"Class_{cls}" for cls in classes_mask_rcnn]

        # Draw bounding boxes and class labels on the image
        image_annotated = image.copy()
        draw = ImageDraw.Draw(image_annotated)

        # Use default font
        try:
            font = ImageFont.truetype("arial.ttf", 20)
        except:
            font = ImageFont.load_default()

        for box, label, score in zip(boxes, classes_mask_rcnn, confidences_mask_rcnn):
            x1, y1, x2, y2 = box
            draw.rectangle([x1, y1, x2, y2], outline="red", width=2)
            label_text = f"{f'Class_{label}'}: {score:.2f}"

            # Calculate the size of the text to create a background
            text_bbox = font.getbbox(label_text)
            text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]
            text_background = [x1, y1 - text_height, x1 + text_width, y1]

            draw.rectangle(text_background, fill="red")
            draw.text((x1, y1 - text_height), label_text, fill="white", font=font)

        # Display the image with bounding boxes
        plt.figure(figsize=(10, 10))
        plt.imshow(image_annotated)
        plt.axis('off')  # Turn off the axes for better visualization
        plt.title(f"Image {i+1}: {os.path.basename(image_path)}")
        plt.show()

        # Save the annotated image to Google Drive
        output_path = os.path.join(image_folder, f"annotated_mask_rcnn_image_{i+1}.jpg")
        image_annotated.save(output_path)

        print(f"Annotated image saved as: {output_path}\n")

        # Store results for this image
        results_list.append({
            'Image': os.path.basename(image_path),
            'Mask R-CNN Detection Time (s)': round(detection_time_mask_rcnn, 2),
            'Mask R-CNN Objects Detected': num_objects_mask_rcnn,
            'Mask R-CNN Classes Detected': class_names_mask_rcnn,
            'Mask R-CNN Confidence Probabilities': [round(conf, 4) for conf in confidences_mask_rcnn],
        })

    except Exception as e:
        print(f"Error processing {image_path}: {e}")

# Step 7: Create a DataFrame to store and display the results
results_df = pd.DataFrame(results_list)

# Display results as a table
print("\nResults Table")
display(results_df)

# Step 8: Save the results as a CSV file in your Google Drive
csv_path = '/content/drive/MyDrive/Assignment3/mask_rcnn_object_detection_results.csv'
results_df.to_csv(csv_path, index=False)

# Print the location of the saved file
print(f"\nResults have been saved to: {csv_path}")

# Step 1: Install required libraries
!pip install ultralytics torch torchvision opencv-python pandas numpy

# Step 2: Import necessary libraries
from ultralytics import YOLO
from PIL import Image, ImageDraw, ImageFont
import matplotlib.pyplot as plt
import os
import pandas as pd
import time  # For tracking detection time
from google.colab import drive

# Step 3: Mount Google Drive
drive.mount('/content/drive')

# Step 4: Initialize YOLO model (using YOLOv8 Medium weights)
model = YOLO("yolov8m.pt")

# Path to the folder containing the images
image_folder = "/content/drive/MyDrive/Assignment3"

# Get list of images (only jpg, png, or jpeg files)
image_paths = [os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.endswith(('.jpg', '.jpeg', '.png'))]

# Limit the number of images to process to 7
image_paths = image_paths[:7]

# Step 5: Results storage
results_list = []

# Step 6: Loop through each image, predict, annotate, and save the results
for i, image_path in enumerate(image_paths):
    try:
        print(f'Processing {image_path}...')

        # Start the timer
        start_time = time.time()

        # Run YOLO prediction on the image
        results = model.predict(image_path)
        result = results[0]  # The result contains detected objects

        # Stop the timer and calculate detection time
        detection_time = time.time() - start_time

        # Extract YOLO detections: boxes, classes, and confidence
        detections = result.boxes.xyxy.cpu().numpy()  # Bounding boxes in [x1, y1, x2, y2] format
        scores = result.boxes.conf.cpu().numpy()  # Confidence scores
        classes = result.boxes.cls.cpu().numpy()  # Class IDs

        # Annotate the image with YOLO-detected objects
        image_annotated = Image.open(image_path).convert("RGB")
        draw = ImageDraw.Draw(image_annotated)
        try:
            font = ImageFont.truetype("arial.ttf", 20)
        except:
            font = ImageFont.load_default()

        # Calculate object areas and relative positions
        image_width, image_height = image_annotated.size
        object_areas = []
        object_positions = []
        for bbox, score, cls in zip(detections, scores, classes):
            x1, y1, x2, y2 = bbox
            width = x2 - x1
            height = y2 - y1
            area = width * height
            object_areas.append(area)

            # Determine relative position
            center_x = (x1 + x2) / 2
            center_y = (y1 + y2) / 2
            if center_x < image_width / 3:
                horizontal = "left"
            elif center_x > 2 * image_width / 3:
                horizontal = "right"
            else:
                horizontal = "center"

            if center_y < image_height / 3:
                vertical = "top"
            elif center_y > 2 * image_height / 3:
                vertical = "bottom"
            else:
                vertical = "middle"

            object_positions.append(f"{vertical}-{horizontal}")

            # Draw bounding box and class label
            cls_name = model.names[int(cls)]
            label_text = f"{cls_name} Conf:{score:.2f}"
            draw.rectangle([x1, y1, x2, y2], outline="red", width=2)
            draw.text((x1, y1 - 10), label_text, fill="white", font=font)

        # Display the annotated image
        plt.figure(figsize=(10, 10))
        plt.imshow(image_annotated)
        plt.axis('off')  # Turn off the axes for better visualization
        plt.title(f"Image {i+1}: {os.path.basename(image_path)}")
        plt.show()

        # Save the annotated image to Google Drive
        output_path = os.path.join(image_folder, f"annotated_image_{i+1}.jpg")
        image_annotated.save(output_path)

        print(f"Annotated image saved as: {output_path}\n")

        # Store results for this image
        results_list.append({
            'Image': os.path.basename(image_path),
            'Detection Time (s)': round(detection_time, 2),
            'Number of Objects Detected': len(detections),
            'Classes Detected': [model.names[int(cls)] for cls in classes],
            'Confidence Probabilities': [round(score, 4) for score in scores],
            'Object Areas': [round(area, 2) for area in object_areas],
            'Relative Positions': object_positions
        })

    except Exception as e:
        print(f"Error processing {image_path}: {e}")

# Step 7: Create a DataFrame to store and display the results
results_df = pd.DataFrame(results_list)

# Display results as a table
print("\nResults Table")
display(results_df)

# Step 8: Save the results as a CSV file in your Google Drive
csv_path = '/content/drive/MyDrive/Assignment3/object_detection_with_areas_positions.csv'
results_df.to_csv(csv_path, index=False)

# Print the location of the saved file
print(f"\nResults have been saved to: {csv_path}")